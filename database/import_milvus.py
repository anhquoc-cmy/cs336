import os
import glob
import pandas as pd
from pymilvus import MilvusClient, DataType

# ================= C·∫§U H√åNH =================
MILVUS_URI = "http://localhost:19530" 
DB_NAME = "default"
COLLECTION_NAME = "AIC_2024_1"
DIMENSION = 1024  # ViT-H-14-378

# ‚ö†Ô∏è QUAN TR·ªåNG: 
# Set = True  : N·∫øu ch·∫°y L·∫¶N ƒê·∫¶U (s·∫Ω x√≥a s·∫°ch d·ªØ li·ªáu c≈© ƒë·ªÉ t·∫°o m·ªõi)
# Set = False : N·∫øu ch·∫°y L·∫¶N 2 tr·ªü ƒëi (ƒë·ªÉ n·∫°p ti·∫øp Batch 2, 3... v√†o m√† kh√¥ng m·∫•t Batch 1)
RESET_DB = False 

DATA_DIR = "./data_for_milvus" # Folder ch·ª©a file parquet

def import_data_to_milvus():
    print(f"Connecting to Milvus at {MILVUS_URI}...")
    client = MilvusClient(uri=MILVUS_URI, db_name=DB_NAME)
    
    # --- B∆Ø·ªöC 1: X·ª¨ L√ù COLLECTION ---
    if RESET_DB:
        # N·∫øu ch·ªçn Reset, x√≥a collection c≈© ƒëi l√†m l·∫°i
        if client.has_collection(COLLECTION_NAME):
            print(f"‚ö†Ô∏è WARNING: Dropping collection {COLLECTION_NAME} because RESET_DB=True")
            client.drop_collection(COLLECTION_NAME)
        
        # T·∫°o Schema m·ªõi (Ch·ªâ t·∫°o khi Reset)
        print("Creating new schema and collection...")
        schema = client.create_schema(auto_id=True, enable_dynamic_field=True)
        
        schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True)
        schema.add_field(field_name="embedding", datatype=DataType.FLOAT_VECTOR, dim=DIMENSION)
        
        # Metadata fields (Kh·ªõp Backend)
        schema.add_field(field_name="video", datatype=DataType.VARCHAR, max_length=100)
        schema.add_field(field_name="frame_id", datatype=DataType.INT64)
        schema.add_field(field_name="time", datatype=DataType.FLOAT)
        schema.add_field(field_name="path", datatype=DataType.VARCHAR, max_length=512)
        # Th√™m tr∆∞·ªùng ASR
        
        # Index Params
        index_params = client.prepare_index_params()
        index_params.add_index(
            field_name="embedding", 
            index_type="IVF_FLAT", # IVF_FLAT c√¢n b·∫±ng t·ªët, n·∫øu RAM d∆∞ d·∫£ (32GB+) c√≥ th·ªÉ d√πng HNSW cho nhanh h∆°n
            metric_type="IP",      # Inner Product (Quan tr·ªçng cho CLIP)
            params={"nlist": 1024}
        )

        client.create_collection(
            collection_name=COLLECTION_NAME,
            schema=schema,
            index_params=index_params
        )
        print(f"‚úÖ Collection {COLLECTION_NAME} created.")
        
    else:
        # N·∫øu kh√¥ng Reset (ch·∫°y Batch 2, 3...), ch·ªâ ki·ªÉm tra xem c√≥ Collection ch∆∞a
        if not client.has_collection(COLLECTION_NAME):
            print("‚ùå Error: Collection not found! Please run with RESET_DB = True for the first batch.")
            return
        print(f"‚ÑπÔ∏è Appending data to existing collection {COLLECTION_NAME}...")

    # --- B∆Ø·ªöC 2: INSERT DATA ---
    parquet_files = glob.glob(os.path.join(DATA_DIR, "*.parquet"))
    print(f"üìÇ Found {len(parquet_files)} parquet files to insert.")
    
    if len(parquet_files) == 0:
        print("‚ö†Ô∏è No parquet files found. Check your DATA_DIR.")
        return

    total_inserted = 0
    for file_path in parquet_files:
        try:
            print(f"Inserting {os.path.basename(file_path)}...", end=" ")
            df = pd.read_parquet(file_path)
            data = df.to_dict('records')
            
            res = client.insert(collection_name=COLLECTION_NAME, data=data)
            count = res['insert_count']
            total_inserted += count
            print(f"‚úÖ OK ({count} vectors)")
            
        except Exception as e:
            print(f"\n‚ùå Failed to insert {file_path}: {e}")

    print("="*30)
    print(f"üéâ DONE! Total vectors inserted: {total_inserted}")
    print("="*30)

if __name__ == "__main__":
    import_data_to_milvus()